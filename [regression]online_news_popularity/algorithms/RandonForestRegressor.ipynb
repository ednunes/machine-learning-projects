{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original = pd.read_csv('../clean_dataset.csv', sep=',', header=0)\n",
    "df = pd.DataFrame(data=df_original)\n",
    "sns.set(style=\"ticks\", color_codes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divisão das informações para treinamento e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df[[c for c in df if c != \"shares\"]]\n",
    "target = df[\"shares\"]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(features, target, test_size=0.3, random_state=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandonForest\n",
    "\n",
    "\n",
    "É um algoritmo de aprendizagem de máquina flexível e fácil de usar que produz excelentes resultados a maioria das vezes, mesmo sem ajuste de hiperparâmetros\n",
    "\n",
    "### Funcionamento\n",
    "\n",
    "Esse algoritmo cria uma “floresta” que é uma combinação de árvores de decisão, na maioria dos casos treinados com o método de bagging. A idéia principal do método de bagging é que a combinação dos modelos de aprendizado aumentando o resultado geral.\n",
    "\n",
    "\n",
    "Sendo mais claro o algoritmo RandonFlorest cria várias árvores de decisão e as combina para obter uma predição com maior acurácia e mais estável.\n",
    "\n",
    "O algoritmo de RandonFlorest adiciona aleatoriedade extra ao modelo quando está criando as árvores. Ao invés de procurar pela melhor característica ao fazer a partição de nós, ele busca a melhor característica em um subconjunto aleatório das características. Este processo cria uma grande diversidade, o que geralmente leva a geração de modelos melhores.\n",
    "\n",
    "\n",
    "\n",
    "## Importância das caracteristicas\n",
    "\n",
    "Outra grande qualidade do RandonForest é a facilidade para se medir a importância relativa de cada característica (feature) para a predição. \n",
    "\n",
    "\n",
    "Sklearn provê uma excelente ferramenta para isto, que mede a importancia das características analisando quantos nós das árvores, que usam uma dada característica, reduzem impureza geral da \"floresta\". Ele calcula este valor automaticamente para cada característica após o treinamento e normaliza os resultados para que a soma de todas as importancias seja igual a 1.\n",
    "\n",
    "\n",
    "Através da inspeção da importância das características, você pode decidir quais características deixar de fora do modelo, já que eles não contribuem o suficiente ou nada para o processo de predição. Isto é importante, porque uma regra geral em aprendizagem de máquina é que quanto mais características você tem, mais provavelmente seu modelo irá sofrer de superajuste (overfitting) e vice versa.\n",
    "\n",
    "\n",
    "## Diferenças\n",
    "\n",
    "\n",
    "Se você treinar uma árvore de decisão com um dataset de treinamento e rótulos, ela vai elaborar um conjunto de regras que serão utilizadas para realizar predições.\n",
    "\n",
    "Por exemplo, se você quiser prever se uma pessoa vai clicar em um anúncio online, você pode colecionar anúncios que a pessoa clicou no passado e algumas características que descrevam esta decisão. Se você colocar as características e rótulos em uma árvore de decisão ela vai gerar nos e algumas regras. Você poderá então prever ser o anúncio será clicado ou não. Quando uma árvore de decisão gera regras e nodos, normalmente utiliza calculos de ganho de informação. Por outro lado, a RandonFlorest faz isto de modo aleatório.\n",
    "\n",
    "Outra diferença é que árvores de decisão profundas podem sofrer de sobreajuste (overfitting). RandonFlorest evitam o sobreajuste na maioria dos casos, pois trabalha com subconjuntos aleatórios das características e constrói árvores menores a partir de tais subconjuntos. Depois do treinamento, as subárvores são combinadas. Esta abordagem torna a computação mais lenta, dependendo de quantas árvores serão construiídas pelo Floresta Aleatória.\n",
    "\n",
    "\n",
    "## Hiperparâmetros Importantes\n",
    "\n",
    "### Aumentando o poder de predição\n",
    "**n_estimators**\n",
    ", que indica o número de árvores construídas pelo algoritmo antes de tomar uma votação ou fazer uma média de predições. Em geral, uma quantidade elevada de árvores aumenta a performance e torna as predições mais estáveis, mas também torna a computação mais lenta.\n",
    "\n",
    "**max_features**, que indica o número máximo de características a serem utilizadas pelo Floresta Aleatória na construção de uma dada árvore. Sklearn oferece várias opções, descritas na sua documentação.\n",
    "\n",
    "**min_sample_leaf** Este parâmetro indica o número mínimo de folhas que devem existir em uma dada árvore.\n",
    "\n",
    "### Aumentando a velocidade do modelo\n",
    "**n_jobs** informa quantos processadores o algoritmo pode utilizar. Se ele tiver valor 1, pode utilizar apenas um processador. O valor -1 significa que não há limite na quantidade de processadores a ser utilizada.\n",
    "\n",
    "**random_state** torna o resultado do modelo replicável. O modelo será produzido do mesmo modo se ele tiver um valor definido de random_state e se forem utilizados os mesmos parâmetros com o mesmos dados de treinamento.\n",
    "\n",
    "**oob_score**(também chamado de oob sampling), que é um método de validação cruzada para floresta aleatória. Neste tipo de amostragem (sampling), cerca de um terço dos dados não é utilizado no treinamento e pode ser utilizado para avaliar a performance. Estas amostras são chamadas out of the bag samples. É uma técnica similar ao método de validação cruzada leave one out, mas sem nenhum custo computacional extra.\n",
    "\n",
    "## Resumo\n",
    "\n",
    "- Muito bom para primeiros estágios de criação de desenvolvimento de um modelo\n",
    "- Provê um bom indicador de importância para as características;\n",
    "- Apresenta boa perfomance;\n",
    "- É possível trabalhar com diferentes tipos de entrada\n",
    "\n",
    "geralmente rápida, simples e flexível embora ainda apresente limitações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance\n",
      "Average Error: 1833.7951 degrees.\n",
      "Accuracy = -13.50%.\n",
      "\n",
      "Feature Importance\n",
      "\n",
      "kw_avg_avg: 23.111661%\n",
      "kw_max_avg: 7.398560%\n",
      "self_reference_avg_sharess: 7.041871%\n",
      "self_reference_min_shares: 6.657751%\n",
      "LDA_04: 3.195387%\n",
      "kw_avg_max: 2.707193%\n",
      "Unnamed: 0: 2.564403%\n",
      "LDA_01: 2.384527%\n",
      "num_imgs: 2.198640%\n",
      "global_subjectivity: 2.138951%\n",
      "kw_min_avg: 2.093098%\n",
      "average_token_length: 2.088474%\n",
      "kw_avg_min: 2.049406%\n",
      "num_hrefs: 2.015787%\n",
      "n_unique_tokens: 1.986279%\n",
      "Unnamed: 0.1: 1.928028%\n",
      "self_reference_max_shares: 1.800752%\n",
      "LDA_00: 1.786278%\n",
      "n_non_stop_unique_tokens: 1.777405%\n",
      "LDA_02: 1.670280%\n",
      "kw_max_min: 1.632339%\n",
      "n_tokens_content: 1.603699%\n",
      "avg_negative_polarity: 1.582350%\n",
      "LDA_03: 1.547931%\n",
      "global_sentiment_polarity: 1.464608%\n",
      "title_subjectivity: 1.419140%\n",
      "avg_positive_polarity: 1.347295%\n",
      "global_rate_positive_words: 1.271624%\n",
      "global_rate_negative_words: 1.143909%\n",
      "kw_min_max: 1.104748%\n",
      "abs_title_sentiment_polarity: 1.039361%\n",
      "title_sentiment_polarity: 0.887242%\n",
      "rate_negative_words: 0.771004%\n",
      "max_negative_polarity: 0.746844%\n",
      "rate_positive_words: 0.670788%\n",
      "min_negative_polarity: 0.573548%\n",
      "min_positive_polarity: 0.487091%\n",
      "n_tokens_title: 0.484145%\n",
      "num_self_hrefs: 0.474131%\n",
      "max_positive_polarity: 0.461160%\n",
      "abs_title_subjectivity: 0.428976%\n",
      "num_keywords: 0.263337%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def evaluate(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    errors = abs(predictions - test_labels)\n",
    "    mape = 100 * np.mean(errors / test_labels)\n",
    "    accuracy = 100 - mape\n",
    "    print('Model Performance')\n",
    "    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
    "    print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "\n",
    "regr =  RandomForestRegressor(max_depth=100,max_features=30, random_state=0, \n",
    "                              min_samples_leaf=60 ,min_samples_split=20,\n",
    "                              n_estimators=100,n_jobs=3)\n",
    "\n",
    "regr.fit(X_train, Y_train)\n",
    "\n",
    "base_accuracy = evaluate(regr, X_test, Y_test)\n",
    "\n",
    "print(\"\\nFeature Importance\\n\")\n",
    "features_importance = zip(regr.feature_importances_, features)\n",
    "for importance, feature in sorted(features_importance, reverse=True):\n",
    "    print(\"%s: %f%%\" % (feature, importance*100)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance\n",
      "Average Error: 1867.6129 degrees.\n",
      "Accuracy = -17.28%.\n",
      "\n",
      "Feature Importance\n",
      "\n",
      "kw_avg_avg: 11.363578%\n",
      "kw_max_avg: 3.630947%\n",
      "self_reference_min_shares: 3.528921%\n",
      "self_reference_avg_sharess: 3.474756%\n",
      "average_token_length: 3.292514%\n",
      "LDA_01: 3.198821%\n",
      "LDA_04: 3.167312%\n",
      "kw_avg_max: 3.127554%\n",
      "avg_positive_polarity: 2.986008%\n",
      "global_subjectivity: 2.898667%\n",
      "LDA_03: 2.765580%\n",
      "n_tokens_content: 2.675234%\n",
      "LDA_00: 2.635473%\n",
      "global_sentiment_polarity: 2.633790%\n",
      "n_unique_tokens: 2.601172%\n",
      "kw_avg_min: 2.579613%\n",
      "num_hrefs: 2.577746%\n",
      "n_non_stop_unique_tokens: 2.530502%\n",
      "LDA_02: 2.488869%\n",
      "kw_min_avg: 2.324815%\n",
      "kw_max_min: 2.302124%\n",
      "avg_negative_polarity: 2.294652%\n",
      "Unnamed: 0.1: 2.252674%\n",
      "global_rate_positive_words: 2.251337%\n",
      "num_imgs: 2.097454%\n",
      "global_rate_negative_words: 2.057286%\n",
      "Unnamed: 0: 2.037663%\n",
      "n_tokens_title: 1.978580%\n",
      "title_sentiment_polarity: 1.908732%\n",
      "self_reference_max_shares: 1.764882%\n",
      "max_negative_polarity: 1.506894%\n",
      "kw_min_max: 1.410838%\n",
      "num_self_hrefs: 1.401676%\n",
      "title_subjectivity: 1.331563%\n",
      "rate_negative_words: 1.081780%\n",
      "abs_title_sentiment_polarity: 1.030361%\n",
      "rate_positive_words: 0.954480%\n",
      "min_positive_polarity: 0.898469%\n",
      "min_negative_polarity: 0.845397%\n",
      "max_positive_polarity: 0.751515%\n",
      "abs_title_subjectivity: 0.728198%\n",
      "num_keywords: 0.631570%\n"
     ]
    }
   ],
   "source": [
    "# Passando outros parametros\n",
    "\n",
    "regr =  RandomForestRegressor(max_depth=13, random_state=0,n_estimators=100,n_jobs=6,)\n",
    "\n",
    "regr.fit(X_train, Y_train)\n",
    "\n",
    "base_accuracy = evaluate(regr, X_test, Y_test)\n",
    "\n",
    "print(\"\\nFeature Importance\\n\")\n",
    "features_importance = zip(regr.feature_importances_, features)\n",
    "for importance, feature in sorted(features_importance, reverse=True):\n",
    "    print(\"%s: %f%%\" % (feature, importance*100)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Técnica de Grid Search\n",
    "\n",
    "Vimos que os melhores valores para esses parâmetros mudam conforme os dados mudam, conforme você adiciona ou tira features e conforme muda os outros parâmetros também.\n",
    "\n",
    "Mas então, como definir quais os melhores valores? \n",
    "\n",
    "Uma das técnicas que pode ser utilizada para isso é o Grid Search CV. \n",
    "\n",
    "Você passa para ele uma lista de possíveis valores e o score usado para medir a eficiência do modelo, ele vai rodar o Cross Validation com todas as possíveis combinações e no final vai te dizer qual a combinação apresentou o melhor score.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 216 candidates, totalling 648 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  35 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=3)]: Done 156 tasks      | elapsed:   29.2s\n",
      "[Parallel(n_jobs=3)]: Done 359 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 642 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=3)]: Done 648 out of 648 | elapsed:  2.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'max_depth': 10,\n",
       "  'max_features': 3,\n",
       "  'min_samples_leaf': 5,\n",
       "  'min_samples_split': 12,\n",
       "  'n_estimators': 40},\n",
       " 0.07191071144364523)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'max_features': [2, 3],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [20, 30, 40, 35]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator = regr, param_grid = param_grid,cv = 3, n_jobs = 3, verbose = 2)\n",
    "\n",
    "\n",
    "grid_search.fit(X_train, Y_train)\n",
    "\n",
    "rgr_rf = grid_search.best_estimator_ \n",
    "grid_search.best_params_, grid_search.best_score_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
